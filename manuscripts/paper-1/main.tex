\documentclass{llncs}
\usepackage[colorlinks,allcolors=blue]{hyperref}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{verbatim}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{cleveref}
\usepackage{tabularray}
\usepackage{dirtree,array}



\graphicspath{{./images/}}

\begin{document}

    \title{Quality assurance of digital twins -- An experience report in the automotive industry}

    \author{Georg Hackenberg\inst{1}
    \and
    Alican Tüzün\inst{1}
    }
    \institute{School of Engineering\\
    University of Applied Sciences Upper Austria\\
    4600 Wels, Upper Austria, Austria\\
    \email{lncs@springer.com}}
    
    \maketitle

    \begin{abstract}
        Digital twins are becoming more and more important for the efficient and effective development and operation of cyber-physical systems.
        However, digital twins are only useful if they reflect the real-world system accurately enough, i.e.\ their quality is high enough.
        This claim entails the question, of what the term quality in the context of digital twins means and how it can be measured.
        In this article, we present our experience with the quality assurance of a digital twin for an assembly line in the automotive industry.
        We explain our preliminary definition of digital twin quality, which we derive from classical quality models for general software systems.
        Furthermore, we describe quality issues, which we were able to detect in a digital twin of an assembly line in the automotive industry.
        Finally, we conclude how to leverage our experience in different contexts and how to generalize the underlying approaches.
    \end{abstract}

    \section{Introduction}\label{section:introduction}
    
    The notion of the digital twin, which has gained popularity in 
    recent years, is often subject to vague and ambiguous envisions\cite{Review1}.
    The mispresenting of this notion began with the physical twin of the Apollo 13 spacecraft. 
    The twin of Apollo 13 was merely a tangible replication of the spacecraft that has been utilized in physical simulations. 
    Even though the digital aspect was expected to be present, there wasn't\cite{GrievesApollo13}.
    Another physical twin is the historic D-day map (also known as the Big Board) in Southwick House England, 
    which was used simultaneously before and during the operation, and can be argued to be similar. 
    The board was a twin of the operation, and it included models of battalions and ships that reflected the actual 
    locations of the corresponding formations. Furthermore, synchronization was 
    implemented to give directives from the real system to control the operation 
    flow and to update the physical twin state\cite{AMRC}.
    In contrast, a digital twin is a virtual counterpart of a real system, which should 
    be synchronized with a selected frequency and fidelity\cite{Review1,Review2,digitaltwinconsortium2022}.
    
    The envision of a digital twin emerged from Grieves'es conceptual model, which was called mirrored spaces model in 2002~\cite{Originsofdigitaltwinconcept},
    and later referenced in a 2005 journal article~\cite{2005JournayArticle}. 
    Furthermore, he introduced the information mirroring model, which was his ideal product lifecycle management tool with only one goal. 
    The goal was to gather enhanced information about the real system to minimize the waste of the system's sources such as energy, 
    time and material. Initially, this model had four main parts. The real system, 
    virtual system, connection between the real and virtual system and virtual simulations\cite{GrievesPLMBook}. 
    Later, Grieves removed the latter, to simplify the model\cite{Originsofdigitaltwinconcept}. Lastly, after co-authoring with Vicker in 2010, 
    Grieves decided to use the NASA-invented "Digital Twin" word, instead of the information mirroring model\cite{Originsofdigitaltwinconcept}.
     
    These days, there is evidence that digital twins play a crucial role in the manufacturing industries, 
    life sciences, healthcare, infrastructure and smart cities\cite{Review2}.
    For example, a digital wind farm from General Electric is a good illustration of how building a digital twin helped to design a better turbine, 
    and later is used to collect and analyze the data from the real system for making the process of the real system more efficient \cite{GeneralElectricWindTurbine}. 
    Another fascinating example of the use of digital twins is Philips' virtual heart model. Twin of the heart evolves with the  data generated by ultrasonic sensors to calculate 
    how well the real heart is pumping the blood. This information can be used to predict a potential heart failure, allowing for early intervention and potentially life-saving treatment \cite{PhilipsHearth}. 
    Lastly, FELICE is another interesting example of a digital twin application in manufacturing. In the project, twin models of machines/equipment and 
    agents are utilized to support real-time decision-making and to conduct what-if analysis and experiments. To ensure the quality of these digital twins, a specific Verification \& Validation process is implemented ~\cite{FELICE}.
    
    The previous studies predominantly focused on the design and implementation of digital twins\cite{Review1, Review2}. 
    However, a crucial aspect that remains unclear is how to achieve quality in these highly intricate and evolvable systems. 
    Therefore, ascertaining the requisite level of quality of a digital twin is an arduous undertaking that requires further research.

    This paper aims to review the digital twin artifacts utilized in the FELICE project and evaluate the quality issues associated with FELICE's digital twin system~\cite{FELICE}. 
    The evaluation aims to enhance the scientific understanding of the quality of digital twins. The artifacts analyzed in this study include process videos showing the current assembly procedure, 
    a scope definition, a requirements specification, a general and operational conceptual model, and a discrete event simulation module. 
    To evaluate these artifacts, we considered five crucial quality attributes: correctness, completeness, fidelity, efficiency, and evolvability.

    \section{State of the art on quality}
    The Oxford English Dictionary defines the word "quality" as a noun or an adjective form. The adjective form indicates, 
    a high standard of excellence as in  "quality products" \cite{OxfordDictionary}. Even though the noun form is defined in multiple ways, the most impactful 
    definition refers to a  standard of an entity that is measured relative to other entities, whether different or similar \cite{OxfordDictionary}.  
    Additionally, quality is the degree to which a set of inherent properties of an entity fulfills the given requirements~\cite{ISO9000}.
    Both of these definitions clearly show the relative aspect of quality, and the following subcategories are the specialization of these definitions.
    \subsection{Product quality}
    A product is a tangible or intangible system that satisfies the needs or wants of a customer. 
    A product can be a physical system like a car, or an abstract system, like a digital twin. Furthermore, product quality is comprised of two aspects~\cite{GrievesPLMBook}.  
    Firstly, quality is an attribute of a product, which refers to the degree to which a product meets its specifications. These product specifications are mostly defined by the supra-systems' subsystems, such as the stakeholders.
    For this aspect, if the stakeholders' expectations or needs are met,  high quality is considered. The second aspect of product quality is the ability to execute to a specific usage standard.
    Unlike the first aspect, standardization is not controllable. Therefore, the product's quality is determined by how well the implied or obligatory standards are met~\cite{GrievesPLMBook}.

    \subsection{Software quality}
    Software is a combination of programs and data that can be utilized by both virtual and physical systems, 
    such as computer systems\cite{OxfordDictionary}. Its quality is determined by how well it fulfills the requirements that were set. However, 
    those requirements may not always reflect the needs of the stakeholders, hence the quality depends on how accurately these requirements were set \cite{IEE730-2014}. 
    As an example, ISO/IEC:25010 has standardized eight attributes, 
    including functional suitability, performance efficiency, compatibility, usability, reliability, security, maintainability, and portability, to measure software quality.
    
    \subsection{Simulation Quality}
    The human brain simulates real systems abstractly either to predict the future state of the system or to gather information about the past state of the system 
    \cite{MobusSystemTheory}. However, these days, many simulation processes are done by virtual systems. For example,  software programs such as ANSYS\cite{Ansys}, ABAQUS\cite{Abaqus}, and AnyLogic\cite{AnyLogic} enable users 
    to build a simulation model to make predictions and get information about the past - as well as the current state - of the system.  
    Quality characteristics of these simulation models must be evaluated by the validation and verification techniques \cite{StewartSimulation} \cite{VerificationValidationSergent} \cite{OsmanBalci}. 

    Validation is the process of evaluating the simulation quality in comparison to the real system from the perspective of its intended applications. 
    On the other hand, verification is a procedure to evaluate the implementation of the simulation model and 
    its associated data concerning the conceptual description and specifications of the model developer\cite{StewartSimulation}\cite{VerificationValidationSergent}. 
    These techniques are broadly categorized into six areas: informal, static, dynamic, 
    symbolic, constraint, and formal techniques \cite{balcicategories}\cite{balcitechniques}. Formal techniques involve mathematical formality, whereas informal techniques rely on 
    human intervention and reasoning. Although mathematical techniques are more precise, informal techniques are more commonly used \cite{balcicategories}. 

    \subsection{Digital twin quality}
    To analyze the state of the digital twin quality, a literature analysis was executed. 
    The analysis especially focused on how the digital twin quality is mentioned and assessed within the academic dissertations. Therefore, various tools, such as Scopus and Google Scholar were 
    used to perform an extensive literature analysis on digital twin publications. However, due to the vast amount of available literature, the scope of the research was narrowed down, resulting in the identification of 
    150 dissertations linked to digital twin quality, verification and validation. After a thorough review of these, only 17 were considered relevant for this paper, and as a result following findings were revealed.
  
    
    First, He Zhang et al. developed a consistency evaluation approach for digital twin models, which can be used to assess their quality. 
    The authors also discuss essential concepts, such as consistency between real and virtual systems and ultra-fidelity models~\cite{ZHANGEVALUATIONMETHOD}. 

    He Zhang et al. introduced the updating method for digital twin models in yet another insightful article.
    Once more, the accuracy and coherence of the model concepts were addressed~\cite{ZHANGUPDATEMETHOD}.

    Selch et al. presented a machine-learning approach based on Bayesian networks to track the quality of the digital twin. 
    The unique aspect of this study is that the authors determined the contributions of subsystems to forecast the overall quality of the digital twin, 
    rather than just analyzing it as a single system. The digital couplings, which are linkages between the subsystems, are also identified as a source of extra uncertainty. 
    However, since only one digital twin has been used in practice, multiple subsystem digital twins have not been validated~\cite{QualityMonitoringofCoupledDigitalTwins}.

    Additionally, the stability of digital twin models was assessed by another study using the Kolmogorov-Smirnov statistical test, 
    which measures the degree of similarity between the probability distribution of the model's predictions and the distribution of the actual data~\cite{RadarDigitalTwin}.

    Edward Y. Hua et al. identify five open problems with digital twin model validation, including modeling realism, data uncertainty, system dynamics, use-case alignment, and reporting invalid modes.
    To address these challenges, the authors propose a digital-twin model validation framework. The paper also highlights three areas for future research, 
    including uncertainty and sensitivity analysis, model validation of system-of-systems, and combining expert knowledge and collected data ~\cite{ValidationofDigitalTwins}. 

    Finally, Shotaro Hamato et al. demonstrated successful real-time anomaly detection using the Unscented Kalman Filter with the digital twin model. 
    However, determining the appropriate threshold for anomaly detection remains problematic~\cite{JapeneseKalmanFilterCorrectness}.

    These dissertations provide valuable insights into various aspects of digital twin quality assessment, including model consistency, stability, and validation, as well as machine learning-based approaches and real-time anomaly detection. 
    However, the identified open problems, including modeling realism, data uncertainty, system dynamics, use-case alignment, and reporting invalid modes, call for further research in the field to improve the quality and reliability of digital twins. Moreover, 
    the lack of well-defined quality parameters for digital twins puts forward a significant challenge in ensuring their quality, which necessitates the development of appropriate quality metrics and standards for digital twins.
  
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Method}
    The methodology consists of a set of artifacts, manual artifact reviews, mapping quality attributes to the findings, an evaluation of the artifact quality, and lastly, an evaluation of the digital twin quality.   
    \subsection{Artifacts}\label{section:Artifacts}
    The current stage of review encompasses five key artifacts, including process videos displaying the current assembly procedure without an adaptive workstation and cobot, a scope definition outlining the objects on the shop floor requiring tracking or twinning, a requirements specification summarizing functional and non-functional requirements for the digital twin, a general and an operational conceptual model elucidating the high-level structure of the assembly procedure, 
    and a discrete event simulation module that implements the structures prescribed by the conceptual models.

    \textbf{Process Videos} have been utilized to explain the manual assembly procedures performed at each of the three workstations. From the three videos initially provided by the project partner,  
    the sequence of assembly steps was extracted at least for one product variant. The tools and the parts needed for each assembly operation were observed. Additionally, the approximate duration of each assembly step 
    was estimated, and some ergonomic characteristics of each operation were derived. 
    The derivable ergonomic characteristics mainly included the poses and motions performed by the operators.

    \textbf{Scope Definition} was determined using a methodology based on hierarchical task analysis and process videos provided by the project partner, which aids in better understanding the context and focus of the digital twin.
    This resulted in a scope definition that identified entities to be twinned, entities to be tracked, and important areas in the scene. 
    Entities to be twinned needed to be represented accurately in the simulation models, including their position, pose, speed, fatigue, and other state variables. 
    Entities to be tracked, on the other hand, only required position information. The scope definition was based on a floor plan of the production facility, with the three workstations marked as gray rectangles. 
    The human workers, cobot, and adaptive workstation were identified as entities to be twinned, and therefore required accurate representation, 
    monitoring, and simulation. Other entities, such as an AGV, carts with doors, and screwdrivers used for assembly operations, were designated as entities to be tracked.

    \textbf{Requirements Specification} for the digital twin was defined with a unique ID, a natural language description, an origin, a category, a priority, and a rationale. The ID was used as a reference point for other project artifacts, while the specification described the requirement in a way that allowed for testing of the digital twin implementation. The origin of the requirement was noted to identify the project partner responsible for its creation.
     The category is distinguished between functional and non-functional requirements, as well as constraints and standards. The priority of each requirement was classified into four levels 
    (must-, should-, could-, and would-have) to help prioritize development efforts. 
    Finally, the rationale provided a clear explanation for each requirement's implication in the specification.

    \textbf{Conceptual Model} was comprised of two parts: a general conceptual model and an operational conceptual model. 
    Both models described the assembly line processes however the operational conceptual model focused on the specific steps of the assembly process, while the general conceptual model focused on higher-level processes and workflows.
    The general conceptual model was represented using a general flow chart notation which distinguishes a root node, activity nodes, and decision nodes.
    The operational conceptual model consisted of three spreadsheets, each displaying the sequence of assembly operations performed at one workstation. 
    The assembly operations were divided into macro- and micro-operations, with each macro-operation referring 
    to one part of the final product being assembled, and the micro-operations referring to the individual steps needed to complete the respective macro-operation.

    \textbf{Discrete Event Simulation Model} consisted of seven sections, including two animation sections, two input sections, one output section, one process logic section, and a database section. 
    The animation sections provided a two-dimensional and a three-dimensional representation of the system, 
    which aided in understanding the simulation and debugging purposes. The input sections allowed for the management of inputs to the simulation model, and the output section displayed summary performance indicators about the simulation run. 
    The process logic section contained the process building blocks, such as queues and assembly operations. Lastly, the database section provided an interface to data sources and sinks.
    
    \subsection{Manual Artifact Reviews}
    During the initial stages of the project, when the target system was not yet available,
    there was a lack of observable data about system behavior that could be utilized for validation. 
    Instead, informal and potentially incomplete, inconsistent, or incorrect system descriptions had to be relied upon. 
    Therefore, manual reviews were deemed the most suitable tool to account for the characteristics of this situation.
    The manual review included, audits, inspections, reviews, structural analysis and walkthroughs 
    with the project partners which was inspired by Balci's manual review works \cite{balcitechniques}. 
    
    \subsection{Digital Twin Quality Attributes}\label{section:Digital Twin Quality Attributes}
    To identify the digital twin quality attributes, the following standards, including ISO/IEC:25010, IEE730-2014, ISO9000, and ISO9001, 
    as well as the Oxford dictionary was consulted to 
    synthesize our findings\cite{ISO9000,ISO90012015,ISO/IEC:25010,IEE730-2014, OxfordDictionary}.
    
    \textbf{Correctness} is a  derived word from the adjective correct, which means that something is error-free regarding fact or truth. 
    In the context of the digital twins, the fact or truth is the real system hence, correctness is a grade of quality, 
    that indicates an error between the real system and a digital twin system.
    Meanwhile, the quality of being correct is described by the term accuracy \cite{OxfordDictionary}. 
    
    \textbf{Completeness} is a derived word from the word complete, which can be described as an adjective, attribute, or verb\cite{OxfordDictionary}. 
    The adjectival form used in the study denotes \textit{complete} as a state of having all the necessary or appropriate parts of both systems\cite{OxfordDictionary}.

    \textbf{Fidelity} refers to the degree of exactness with which the real system is copied and represented. 
    Low fidelity indicates a simplified representation, while high fidelity refers to an accurate and detailed representation of the real system \cite{Review2}. 
    The concept of fidelity has garnered significant attention in recent
    years and continues to be an important focus in Digital Twin research\cite{Review2}\cite{Review1}.

    \textbf{Efficiency} refers to the quality of being efficient\cite{OxfordDictionary}. Therefore, efficiency is achieving
    maximum productivity with minimum wasted effort or expense. It is worth mentioning that the concept of efficiency is tightly intertwined with the concept of productivity, 
    although it differs from the latter's definition, which is defined as the ability to produce large amounts of goods\cite{OxfordDictionary}.  
    For example, time efficiency indicates that,  with less amount of time as an input, more output with the minimum waste during the process is desired. 

    \textbf{Evolvability} is a system's capability to enhance its suitability to its environment through alterations to both its internal and functional 
    structure\cite{MobusSystemTheory}. Another term to describe the response to changes in the environment is adaptability.
    However, this concept differs from evolvability in that it only affects a system's internal or functional structure temporarily. 
    For instance, a digital twin, which is an evolvable virtual system, can be designed to be more flexible and scalable, 
    allowing for easy updates and the addition of new features\cite{ZHANGUPDATEMETHOD}.
    
    \subsection{Mapping Digital Twin Attributes to Manual Review Results}
    To evaluate the quality of the artifact, the issues were mapped to digital twin attributes. 
    To begin this process, the findings were collected from the manual review, followed by an inspection of the findings to determine which digital twin qualities were absent. 
    Finally, the findings were mapped to the relevant missing quality attribute(s) and submitted for artifact quality evaluation. 
    
    \subsection{Artifact Quality Evaluation}
    To evaluate the quality of the digital twin artifacts, the mapped findings were scrutinized and evaluated. 
    The process started by identifying which quality attribute(s) were mapped. 
    Once identified, the missing attribute(s) was incremented by 1 to determine the total quality missing attributes of the artifact. 
    
    \begin{figure}[htbp]
        \includegraphics[scale = 0.35]{RequirementSpecifications.png}
        \caption{Method for the evaluation of the digital twin artifact quality: Artifact. finding indicates that the finding belongs to the artifact, while -> indicates mapping}
        \label{fig:Method}
    \end{figure}
    
    \subsection{Digital Twin Quality Evaluation}
    To assess the quality of the digital twin, the values obtained from evaluating each artifact's quality are collected and summed. 
    The resulting sum was assigned to the corresponding digital twin quality attribute. 
    As a result, the digital twin quality was expressed with quality attribute values.    
  

    \begin{figure}[htbp]
        \includegraphics[scale = 0.25]{DigitalTwinQuality.png}
            \caption{Method for the evaluation of the digital twin quality}
        \label{fig:MethodforDigitalTwinQuality}
    \end{figure}
   
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RESULTS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Results}

    First, to assess digital twin quality, manual reviews for each artifact were conducted (Figure~\ref{fig:QualityInspectonResultsWithArtifacts} ). 
    As a result, a total of twenty-one quality issues were identified, listed and finally mapped to the digital twin quality attributes(Table~\ref{tab:Table1})(Table~\ref{tab:Table2})(Figure~\ref{fig:QualityInspectonResultsWithArtifacts}).
    The mapping process revealed that a total of thirty-eight digital twin quality attributes were lacking in the artifacts(Figure~\ref{fig:QualityInspectonResultsWithArtifacts}).  
    Specifically, 24\% of the quality issues of the digital twin were related to correctness, 35\%  were related to completeness, 8\%  were related to fidelity, 5\%  were related to efficiency,
    and finally, 28\% were related to evolvability.  


    \subsection{Example Findings}

    To Three examples illustrate the potential 
    12 - Conceptual Model
    17 - Simulation Model
    20 - Simulation Model
    First: the discrete event simulation model originally enforced a strictly sequential execution of operations.
    However, the human and the cobot can work in parallel, and therefore execute operations also in parallel.
    This issue has been solved already in a later version of the discrete event simulation model.

    F12 - **Even though the durations of the macro-operations were well-known and studied throughly before, the durations of the micro-operations were estimated based on a simple calculation scheme. **Completeness, Correctness.****

    This issue is related to the correctness and completeness of the operational conceptual model. While the durations of the macro-operations are well-known and derived from a previous study, the durations of the micro-operations are estimated based on a simple calculation scheme. This introduces a risk of inaccuracy and incompleteness in the model, which could affect the overall performance of the digital twin. Validating the durations of the micro-operations is necessary to ensure the correctness and completeness of the model, but this validation might not be feasible until the entire
    FELICE system is operational and proper data can be collected. Therefore, this issue should be addressed in the future to ensure the accuracy of the digital twin.


    **F17 - The duration of micro-, loading- and unloading-operations of the cobot were based on assumptions rather than actual measurements.
    **Correctness, Completeness****

    Second: The original discrete event simulation model originally enforced a fixed number of operations per workstation.
    This might be okay for now, but what if the workstations and the workflows change in the future?
    In such cases, adapting the discrete event simulation model might take a substantial some effort.

    **This finding relates to the completeness and fidelity aspects of the DES module. The durations of micro-operations as well as the loading 
    and unloading operations of the cobot are important factors that affect the accuracy of the simulation. The fact that these values are based 
    on assumptions rather than actual measurements means that there is a risk of inaccuracy in the simulation results. In terms of completeness, 
    the module is not able to provide a fully accurate simulation because it is based on assumptions that have not been validated. 
    In terms of fidelity, the module may not accurately reflect the behavior of the real system due to the potential inaccuracy of these assumptions.
    However, it should be noted that this issue is due to limitations in the data collection process rather than any shortcomings in the design of the DES module itself.**

    F20 - **Number of micro-operations were hardcoded, consequently, the DES module must be reprogrammed everytime, when a new micro-operation is needed.** 
    **Evolvability**

    **Based on the given finding, the issue with the process logic section is related to its maintainability and adaptability. 
    The DES module has a hardcoded number of micro-operations that can be performed at a single workstation, which means that the module must be reprogrammed every time 
    a different number of micro-operations is required. This issue could impact the maintainability and adaptability of the DES module. It is suggested that the number of 
    micro-operations per workstation can be configured instead to address this issue. However, it is also mentioned that the current number of micro- 
    and macro-operations allows the generation of 272 workflows, which provides a solid base for look-ahead and optimization purposes and what-if analysis to be executed by a human end-user.**
    

    

    Third: The different workflow variants, that can be executed on the assembly line, are managed entirely manually.
    However, the workflow variants mostly differ in the assignment of operations to human and cobot.
    Therefore, one can imagine a technique to generate workflow variants automatically, which would greatly improve evolvability.
    \begin{table}[h!]
    \begin{center}
    \label{tab:Table2}
    \caption{adfasdfadf}
    \scalebox{0.8}{
        \begin{tabular}{llllll}
            \multicolumn{1}{c} {Findings} & \multicolumn{1}{c} {\textbf{\textit{Correctness}}} & \multicolumn{1}{c}{\textbf{\textit{Completeness}}} 
            & \multicolumn{1}{c}{\textbf{\textit{Fidelity}}} & \multicolumn{1}{c}{\textbf{\textit{Efficiency}}} & \multicolumn{1}{c}{\textbf{\textit{Evolvability}}} \\
            \begin{minipage}{4cm}\dirtree{%
                .1 Artifacts.
                .2 Process Videos.
                .3 Finding 1.
                .2 Scope Definition.
                .3 Finding 2.
                .2 Requirement Spec.
                .3 Finding 3.
                .3 Finding 4.
                .3 Finding 5.
                .3 Finding 6.
                .2 Conceptual Model.
                .3 Finding 7.
                .3 Finding 8.
                .3 Finding 9.
                .3 Finding 10.
                .3 Finding 11.
                .3 Finding 12.
                .2 Simulation Model.
                .3 Finding 13.
                .3 Finding 14.
                .3 Finding 15.
                .3 Finding 16.
                .3 Finding 17.
                .3 Finding 18.
                .3 Finding 19.
                .3 Finding 20.
                .3 Finding 21.
            }\end{minipage}
            &
            \DTsetlength{0pt}{0pt}{0pt}{0pt}{0pt}
            \begin{minipage}{2cm}\dirtree{%
                .1 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
            }\end{minipage}
            &
            \DTsetlength{0pt}{0pt}{0pt}{0pt}{0pt}
            \begin{minipage}{2cm}\dirtree{%
                .1 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
            }\end{minipage}
            &
            \DTsetlength{0pt}{0pt}{0pt}{0pt}{0pt}
            \begin{minipage}{2cm}\dirtree{%
                .1 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
            }\end{minipage}
            &
            \DTsetlength{0pt}{0pt}{0pt}{0pt}{0pt}
            \begin{minipage}{2cm}\dirtree{%
                .1 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
            }\end{minipage}
            &
            \DTsetlength{0pt}{0pt}{0pt}{0pt}{0pt}
            \begin{minipage}{2cm}\dirtree{%
                .1 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .2 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
                .3 ~~~~~x.
            }\end{minipage}
        \end{tabular}
    }
\end{center}
\end{table}
    %TODO BETTER TABLE
    \begin{table}[h!]
    \begin{center}
    \label{tab:Table1}
    \caption{Mapping of digital twin attributes to the results of the manual reviews: In cases where an attribute is mapped, the "artifact.qualityattribute.value" is incremented by 1. }
    \renewcommand{\arraystretch}{1.25}
    \scalebox{0.70}{
    \begin{tabular}{l@{\hspace{1cm}}l@{\hspace{1cm}}l@{\hspace{1cm}}l@{\hspace{1cm}}l@{\hspace{1cm}}l@{\hspace{1cm}}l}
        \textbf{Findings} & \textbf{Correctness} & \textbf{Completeness} & \textbf{Fidelity} & \textbf{Efficiency} & \textbf{Evolvability}\\
        \hline
        \textbf{Process Videos}&~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ \\
        \textbf{Finding 1} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Scope Definition}&~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ \\
        \textbf{Finding 2} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Requirement Specification}&~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ \\
        \textbf{Finding 3} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 4} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 5} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 6} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Conceptual Model}&~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ \\
        \textbf{Finding 7} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 8} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 9} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 10} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 11} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 12} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Simulation Model} &~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ & ~~~~~~~~~~~~~~~~~~~ \\
        \textbf{Finding 13} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 14}&~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 15} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 16} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 17} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 18} &~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ \\
        \textbf{Finding 19} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 20} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \textbf{Finding 21} &~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~0~~~~~~~~~ & ~~~~~~~~~1~~~~~~~~~ \\
        \hline
        \textbf{Total} &~~~~~~~~~9~~~~~~~~~ & ~~~~~~~~~13~~~~~~~~~ & ~~~~~~~~~3~~~~~~~~~ & ~~~~~~~~~2~~~~~~~~~ & ~~~~~~~~~11~~~~~~~~~ \\
    \end{tabular}
    }
    \end{center}
    \end{table}
    
    \begin{figure}[htbp]
        \includegraphics[scale = 0.40]{quality_inspection_results_with_artifacts.png}
        \caption{Quality Inspection Results Categorized with Artifacts: X-Axis represents artifacts in \ref{section:Artifacts}, Y-Axis represents the number of missing quality attributes found for each artifact, 
        and lastly, each digital twin quality attribute is shown by the colors.}
        \label{fig:QualityInspectonResultsWithArtifacts}
    \end{figure}

    

    \section{Discussion}

    The results of this study demonstrate that a manual review and mapping of quality attributes to issues is an effective approach for evaluating the quality of digital twins in the design phase.  
    Therefore, systematic analysis of the identified issues in terms of their relevance to various quality attributes is an effective way to gain insight into the strengths and weaknesses of the digital twin system under development. 
    These insights can be used to guide further design decisions and improvements, ultimately leading to a higher-quality end product.

    The quality assessment of the digital twin encountered some limitations due to the exility of information about the real system. Some artifacts provided less information, 
    such as process videos, which only provide a limited perspective of the shop floor based on the camera's field of view and the skills of the video maker. 
    In contrast, the simulation and conceptual model offer a plethora of aspects to examine and assess, which results in a higher probability of discovering the issues \ref{fig:QualityInspectonResultsWithArtifacts}.

    The reason of why the  most of the issues are related to the evolvability, 
    completeness and correctness, and less for fidelity and efficiency is due to the stage that the FELICE project is in. Not only the exility of the information is the limiting factor, also the visibility of the information 
    is also an interesting factor. Therefore, evolvability, completeness and correctness are easier to map and detect , rather than fidelity and efficiency. 

    Person dependent, also not everything is written, memory problem, completeness, 
    issuee finding sometimes even though the issue is not there, still assesed as a issue, assuming that person is correct

    The write a protocol, timing ,hard to cover everything, 
    

    
    \section*{Acknowledgements}
    TODO

    \bibliography{main}
    \bibliographystyle{splncs04}

\end{document}



        